{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEED_URL='http://www.indeed.com/jobs?q=Data+Scientist&start='\n",
    "\n",
    "#Creates a dataframe with colums for title, company, location, salary and description.\n",
    "indeed_ds=pd.DataFrame(columns=['title','company','location','salary','description'])\n",
    "\n",
    "for i in range (1,10):\n",
    "    if i==0:\n",
    "        print i\n",
    "        r=requests.get(INDEED_URL)\n",
    "        soup=BeautifulSoup(r.text,\"lxml\")\n",
    "        results=soup.findAll('div',{\"class\":\" row result\"}) #+ soup.findAll('div',{\"class\":\"row result\"})\n",
    "        for result in results:\n",
    "            title=''\n",
    "            company=''\n",
    "            location=''\n",
    "            salary=''\n",
    "            description=''\n",
    "            try:\n",
    "                temp=result.select('h2.jobtitle')\n",
    "                title=temp[0].text.strip()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                temp=result.select('span.company')\n",
    "                company=temp[0].text.strip()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                temp=result.select('span.location')\n",
    "                location=temp[0].text.strip()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                temp=result.select('td.snip')\n",
    "                salary=temp[0].text.strip()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                temp=result.select('span.summary')\n",
    "                description=temp[0].text.strip()\n",
    "            except:\n",
    "                pass\n",
    "            indeed_ds.loc[len(indeed_ds)]=[title,company,location,salary,description]            \n",
    "\n",
    "    else:\n",
    "#         if (i%100==0):\n",
    "        print i\n",
    "        INDEED_URL_UNIQUE=INDEED_URL+str(i*10)\n",
    "        r=requests.get(INDEED_URL_UNIQUE)\n",
    "        soup=BeautifulSoup(r.text,\"lxml\")\n",
    "        results=soup.findAll('div',{\"class\":\" row result\"}) #+soup.findAll('div',{\"class\":\"row result\"})\n",
    "        for result in results:\n",
    "            title=''\n",
    "            company=''\n",
    "            location=''\n",
    "            salary=''\n",
    "            description=''\n",
    "            try:\n",
    "                temp=result.select('h2.jobtitle')\n",
    "                title=temp[0].text.strip()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                temp=result.select('span.company')\n",
    "                company=temp[0].text.strip()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                temp=result.select('span.location')\n",
    "                location=temp[0].text.strip()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                temp=result.select('td.snip')\n",
    "                salary=temp[0].text.strip()\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                temp=result.select('span.summary')\n",
    "                description=temp[0].text.strip()\n",
    "            except:\n",
    "                pass\n",
    "            indeed_ds.loc[len(indeed_ds)]=[title,company,location,salary,description]   \n",
    "indeed_ds\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indeed_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(indeed_ds['location'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indeed_ds['description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.indeed.com/q-data-scientist-salary-$50,000-l-New-York-jobs.html\"\n",
    "response = requests.get(URL)\n",
    "html = response.text\n",
    "soup = BeautifulSoup(html, 'html.parser', from_encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rowresult = soup.find_all(\"div\", {\"class\": \" row result\"})[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\" row result\" data-jk=\"413e4af45f2a192a\" data-tn-component=\"organicJob\" id=\"p_413e4af45f2a192a\">\n",
      " <h2 class=\"jobtitle\" id=\"jl_413e4af45f2a192a\">\n",
      "  <a class=\"turnstileLink\" data-tn-element=\"jobTitle\" href=\"/rc/clk?jk=413e4af45f2a192a&amp;fccid=8f0f33c2ec902ebc\" onclick=\"setRefineByCookie(['salest']); return rclk(this,jobmap[0],true,0);\" onmousedown=\"return rclk(this,jobmap[0],0);\" rel=\"noopener nofollow\" target=\"_blank\" title=\"Jr. Research Analyst\">\n",
      "   Jr. Research Analyst\n",
      "  </a>\n",
      " </h2>\n",
      " <span class=\"company\">\n",
      "  ValuePenguin\n",
      " </span>\n",
      " -\n",
      " <span class=\"location\">\n",
      "  New York, NY\n",
      " </span>\n",
      " <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n",
      "  <tr>\n",
      "   <td class=\"snip\">\n",
      "    <div class=\"\">\n",
      "     <span class=\"summary\">\n",
      "      Review and update in-house\n",
      "      <b>\n",
      "       data\n",
      "      </b>\n",
      "      for quality assurance purposes. Analysts will develop proficiency and participate in article writing, consumer research,\n",
      "      <b>\n",
      "       data\n",
      "      </b>\n",
      "      ...\n",
      "     </span>\n",
      "    </div>\n",
      "    <div class=\"result-link-bar-container\">\n",
      "     <div class=\"result-link-bar\">\n",
      "      <span class=\"date\">\n",
      "       30+ days ago\n",
      "      </span>\n",
      "      <span class=\"tt_set\" id=\"tt_set_0\">\n",
      "       -\n",
      "       <a class=\"sl resultLink save-job-link \" href=\"#\" id=\"sj_413e4af45f2a192a\" onclick=\"changeJobState('413e4af45f2a192a', 'save', 'linkbar', false, ''); return false;\" title=\"Save this job to my.indeed\">\n",
      "        save job\n",
      "       </a>\n",
      "       -\n",
      "       <a class=\"sl resultLink more-link \" href=\"#\" id=\"tog_0\" onclick=\"toggleMoreLinks('413e4af45f2a192a'); return false;\">\n",
      "        more...\n",
      "       </a>\n",
      "      </span>\n",
      "      <div class=\"edit_note_content\" id=\"editsaved2_413e4af45f2a192a\" style=\"display:none;\">\n",
      "      </div>\n",
      "      <script>\n",
      "       if (!window['result_413e4af45f2a192a']) {window['result_413e4af45f2a192a'] = {};}window['result_413e4af45f2a192a']['showSource'] = false; window['result_413e4af45f2a192a']['source'] = \"ValuePenguin\"; window['result_413e4af45f2a192a']['loggedIn'] = false; window['result_413e4af45f2a192a']['showMyJobsLinks'] = false;window['result_413e4af45f2a192a']['undoAction'] = \"unsave\";window['result_413e4af45f2a192a']['relativeJobAge'] = \"30+ days ago\";window['result_413e4af45f2a192a']['jobKey'] = \"413e4af45f2a192a\"; window['result_413e4af45f2a192a']['myIndeedAvailable'] = true; window['result_413e4af45f2a192a']['showMoreActionsLink'] = true; window['result_413e4af45f2a192a']['resultNumber'] = 0; window['result_413e4af45f2a192a']['jobStateChangedToSaved'] = false; window['result_413e4af45f2a192a']['searchState'] = \"q=data scientist salary $50,000&amp;l=New+York\"; window['result_413e4af45f2a192a']['basicPermaLink'] = \"https://www.indeed.com\"; window['result_413e4af45f2a192a']['saveJobFailed'] = false; window['result_413e4af45f2a192a']['removeJobFailed'] = false; window['result_413e4af45f2a192a']['requestPending'] = false; window['result_413e4af45f2a192a']['notesEnabled'] = true; window['result_413e4af45f2a192a']['currentPage'] = \"serp\"; window['result_413e4af45f2a192a']['sponsored'] = false;window['result_413e4af45f2a192a']['reportJobButtonEnabled'] = false; window['result_413e4af45f2a192a']['showMyJobsHired'] = false; window['result_413e4af45f2a192a']['showSaveForSponsored'] = false; window['result_413e4af45f2a192a']['showJobAge'] = true;\n",
      "      </script>\n",
      "     </div>\n",
      "    </div>\n",
      "    <div class=\"tab-container\">\n",
      "     <div class=\"more-links-container result-tab\" id=\"tt_display_0\" style=\"display:none;\">\n",
      "      <a class=\"close-link closeLink\" href=\"#\" onclick=\"toggleMoreLinks('413e4af45f2a192a'); return false;\" title=\"Close\">\n",
      "      </a>\n",
      "      <div class=\"more_actions\" id=\"more_0\">\n",
      "       <ul>\n",
      "        <li>\n",
      "         <span class=\"mat\">\n",
      "          View all\n",
      "          <a href=\"/q-Valuepenguin-l-New-York,-NY-jobs.html\" rel=\"nofollow\">\n",
      "           ValuePenguin jobs in New York, NY\n",
      "          </a>\n",
      "          -\n",
      "          <a href=\"/l-New-York,-NY-jobs.html\">\n",
      "           New York jobs\n",
      "          </a>\n",
      "         </span>\n",
      "        </li>\n",
      "        <li>\n",
      "         <span class=\"mat\">\n",
      "          Salary Search:\n",
      "          <a href=\"/salaries/Junior-Research-Analyst-Salaries,-New-York-NY\" onmousedown=\"this.href = appendParamsOnce(this.href, '?campaignid=serp-more&amp;fromjk=413e4af45f2a192a&amp;from=serp-more');\">\n",
      "           Junior Research Analyst salaries in New York, NY\n",
      "          </a>\n",
      "         </span>\n",
      "        </li>\n",
      "        <li>\n",
      "         <span class=\"mat\">\n",
      "          Learn more about working at\n",
      "          <a href=\"/cmp/Valuepenguin\" onmousedown=\"this.href = appendParamsOnce(this.href, '?fromjk=413e4af45f2a192a&amp;from=serp-more&amp;campaignid=serp-more&amp;jcid=dde7eb600d4bf993');\">\n",
      "           Valuepenguin\n",
      "          </a>\n",
      "         </span>\n",
      "        </li>\n",
      "        <li>\n",
      "         <span class=\"mat\">\n",
      "          Related forums:\n",
      "          <a href=\"/forum/cmp/Valuepenguin.html\">\n",
      "           ValuePenguin\n",
      "          </a>\n",
      "          -\n",
      "          <a href=\"/forum/job/Research-Analyst.html\">\n",
      "           Research Analyst\n",
      "          </a>\n",
      "          -\n",
      "          <a href=\"/forum/loc/New-York-New-York.html\">\n",
      "           New York, New York\n",
      "          </a>\n",
      "         </span>\n",
      "        </li>\n",
      "       </ul>\n",
      "      </div>\n",
      "     </div>\n",
      "     <div class=\"dya-container result-tab\">\n",
      "     </div>\n",
      "     <div class=\"tellafriend-container result-tab email_job_content\">\n",
      "     </div>\n",
      "     <div class=\"sign-in-container result-tab\">\n",
      "     </div>\n",
      "     <div class=\"notes-container result-tab\">\n",
      "     </div>\n",
      "    </div>\n",
      "   </td>\n",
      "  </tr>\n",
      " </table>\n",
      "</div>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print rowresult.prettify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing functions to extract the following items:\n",
    "1. Location\n",
    "2. Company\n",
    "3. Job\n",
    "4. Salary\n",
    "5. Description\n",
    "\n",
    "\n",
    "- Make sure these functions are robust and can handle cases where the data/field may not be available.\n",
    "    - Remember to check if a field is empty or `None` for attempting to call methods on it\n",
    "    - Remember to use `try/except` if you anticipate errors\n",
    "- Test the functions on the results above and simple examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_company(cos):\n",
    "    company = \"\"\n",
    "    for entry in cos:\n",
    "        if entry != (\"\" or None):\n",
    "            try:\n",
    "                company = str(entry.find(\"a\").text).lstrip()\n",
    "            except:\n",
    "                company = \"No Company Listed\"\n",
    "        else:\n",
    "            company = \"No Company Listed\"\n",
    "    return company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No Company Listed'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_company(soup.find_all(\"span\", {\"class\": \"company\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_salary(salaries):\n",
    "    for entry in salaries:\n",
    "        if entry != (\"\" or None):\n",
    "            try:\n",
    "                salary = str(entry.find(\"nobr\").text).lstrip()\n",
    "            except:\n",
    "                salary = \"No Salary Listed\"\n",
    "        else:\n",
    "            salary = \"No Salary Listed\"\n",
    "    return salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No Salary Listed'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_salary(soup.find_all(\"td\",{\"class\":\"snip\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_jobtitle(titles):\n",
    "    for entry in titles:\n",
    "        if entry != (\"\" or None):\n",
    "            try:\n",
    "                jobtitle = str(entry.text).lstrip()\n",
    "            except:\n",
    "                jobtitle = \"No Job Title Listed\"\n",
    "        else:\n",
    "            jobtitle = \"No Job Title Listed\"\n",
    "    return jobtitle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Junior Economic Data Analyst'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_jobtitle(soup.find_all(\"a\", {\"data-tn-element\":\"jobTitle\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location(locations):\n",
    "    for entry in locations:\n",
    "        if entry != (\"\" or None):\n",
    "            try:\n",
    "                location = str(entry.text).lstrip()\n",
    "            except:\n",
    "                location = \"No Location Listed\"\n",
    "        else:\n",
    "            location = \"No Location Listed\"\n",
    "    return location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'West Point, NY'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_location(soup.find_all(\"span\", {\"class\":\"location\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_description(description):\n",
    "    for entry in description:\n",
    "        if entry != (\"\" or None):\n",
    "            try:\n",
    "                description = str(entry.text).lstrip()\n",
    "            except:\n",
    "                description = \"No Description Listed\"\n",
    "        else:\n",
    "            description = \"No Description Listed\"\n",
    "    return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Salary Dependent on Experience; Junior Economic Data Analyst or go to:. Comprised primarily of economists, but also political scientists, data analysts,...'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_description(soup.find_all(\"span\", {\"class\":\"summary\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To scale up the scraping, we need to get results from more locations. \n",
    "\n",
    "Now, to scale up our scraping, we need to accumulate more results. We can do this by examining the URL below.\n",
    "\n",
    "- \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\"\n",
    "\n",
    "There are two queries to modify to collect more results:\n",
    "- `l=New+York`\n",
    "- `start=10`\n",
    "\n",
    "The first controls the location of the result and the second is the results pages (by incrementing this number we are able to go further into the search results). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following codes are to modify the cities of the search parameter.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_template = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l={}&start={}\"\n",
    "\n",
    "max_results_per_city = 10 # Set this to a high-value (5000) to generate more results. \n",
    "# A larger number will take a longer period of time. First test your code on a small number of results and then expand.\n",
    "\n",
    "results = []\n",
    "\n",
    "for city in set(['New+York', 'Chicago', 'San+Francisco', 'Austin', 'Seattle', \n",
    "    'Los+Angeles', 'Philadelphia', 'Atlanta', 'Dallas', 'Pittsburgh', \n",
    "    'Portland', 'Phoenix', 'Denver', 'Houston', 'Miami', 'California']):\n",
    "        for start in range(0, max_results_per_city, 10):\n",
    "            url = \"https://www.indeed.com/jobs?q=data+scientist+%2445%2C000&l=\"+str(city)+\"&start=\"+str(start)\n",
    "            response = requests.get(url)\n",
    "            html = response.text\n",
    "            results.append(html)\n",
    "        # Grab the results from the request (as above)\n",
    "        # Append to the full set of results\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_50 = ''.join(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_50 = BeautifulSoup(r_50, 'html.parser', from_encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** Using the fuctions above to parse the 5 fields; location, title, company, salary and description. Create a dataframe to store the results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds50 = pd.DataFrame(columns=['location', 'title', 'company', 'salary', 'description'])\n",
    "ds70 = pd.DataFrame(columns=['location', 'title', 'company', 'salary', 'description'])\n",
    "ds85 = pd.DataFrame(columns=['location', 'title', 'company', 'salary', 'description'])\n",
    "ds100 = pd.DataFrame(columns=['location', 'title', 'company', 'salary', 'description'])\n",
    "ds115 = pd.DataFrame(columns=['location', 'title', 'company', 'salary', 'description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in soup_50.find_all('div', {'class': ' row result'}):\n",
    "    location = get_location(soup.find_all(\"span\", {\"class\":\"location\"}))\n",
    "    jobtitle = get_jobtitle(soup.find_all(\"a\", {\"class\":\"turnstileLink\"}))\n",
    "    company = get_company(soup.find_all(\"span\", {\"class\":\"company\"}))\n",
    "    salary = get_salary(soup.find_all(\"td\", {\"class\":\"snip\"}))\n",
    "    description = get_description(soup.find_all(\"span\", {\"class\":\"summary\"}))\n",
    "    ds50.loc[len(ds50)]=[location, jobtitle, company, salary, description] #Makes a new record in the created dataframe with the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "r_70 = ''.join(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "soup_70 = BeautifulSoup(r_70, 'html.parser', from_encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for row in soup_70.find_all('div', {'class': ' row result'}):\n",
    "    location = get_location(soup.find_all(\"span\", {\"class\":\"location\"}))\n",
    "    jobtitle = get_jobtitle(soup.find_all(\"a\", {\"class\":\"turnstileLink\"}))\n",
    "    company = get_company(soup.find_all(\"span\", {\"class\":\"company\"}))\n",
    "    salary = get_salary(soup.find_all(\"td\", {\"class\":\"snip\"}))\n",
    "    description = get_description(soup.find_all(\"span\", {\"class\":\"summary\"}))\n",
    "    ds70.loc[len(ds50)]=[location, jobtitle, company, salary, description] #Makes a new record in the created dataframe with the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a list of dataframes\n",
    "dfs = [ds50, ds70, ds85, ds100, ds115]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a save point to ensure all the data is backed up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for x in dfs:\n",
    "    x.to_csv(str(counter)+'.csv')\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we need to clean up salary data. \n",
    "\n",
    "1. Only a small number of the scraped results have salary information - only these will be used for modeling.\n",
    "1. Some of the salaries are not yearly but hourly or weekly, these will not be useful to us for now\n",
    "1. Some of the entries may be duplicated\n",
    "1. The salaries are given as text and usually with ranges.\n",
    "\n",
    "#### Find the entries with annual salary entries, by filtering the entries without salaries or salaries that are not yearly (filter those that refer to hour or week). Also, remove duplicate entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a new column for the salary ranges from the filter searches that we made, called salrange and we will use the lower bracket of the value that we will use to impute the missing values after getting rid of duplicated records and then merging the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds20['salrange'] = 20000\n",
    "ds60['salrange'] = 60000\n",
    "ds100['salrange'] = 100000\n",
    "ds140['salrange'] = 140000\n",
    "ds180['salrange'] = 180000\n",
    "ds220['salrange'] = 220000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Checking for missing values\n",
    "for x in dfs:\n",
    "    print x.isnull().sum.sort_values(ascending=False)[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x in dfs:\n",
    "    print x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Concatenate all dataframes into 1\n",
    "df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Size of df after concatenating all the 5 dataframes together\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Remove any duplicates over the 4 features\n",
    "df.drop_duplicates(['location', 'salary', 'company', 'title', 'description'], keep='last', inplace=True)\n",
    "\n",
    "#Keep = 'last' was used to ensure that the value with the upper bound in salary range was kept rather than the lower bound for any duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Size of df after dropping duplicates\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
